# ------------------------------------------------------------------------
# PoET: Pose Estimation Transformer for Single-View, Multi-Object 6D Pose Estimation
# Copyright (c) 2022 Thomas Jantos (thomas.jantos@aau.at), University of Klagenfurt - Control of Networked Systems (CNS). All Rights Reserved.
# Licensed under the BSD-2-Clause-License with no commercial use [see LICENSE for details]
# ------------------------------------------------------------------------

import json
import os

# Parameter Initialization
train_set = "synt_only"  # Choices: full, real_only, synt_only, pbr_only, real_synt
test_set = "full"  # Choices: full, keyframes, bop

for annotation_set in ["train", "test_all"]:

    if annotation_set == "train":
        if train_set == "full":
            # Annotate the full train dataset
            data_paths = ['train_real/', 'train_synt/', 'train_pbr/']
            img_types = ['real', 'synt', 'pbr']
            annotation_path = 'train.json'
            only_keyframes = False
        elif train_set == "real_only":
            # Annotate only the real images
            data_paths = ['train_real/']
            img_types = ['real']
            annotation_path = 'train.json'
            only_keyframes = False
        elif train_set == "synt_only":
            # Annotate only the synthetic images
            data_paths = ['train_synt/']
            img_types = ['synt']
            annotation_path = 'train.json'
            only_keyframes = False
        elif train_set == "pbr_only":
            # Annotate only the images generated by PBR
            data_paths = ['train_pbr/']
            img_types = ['pbr']
            annotation_path = 'train.json'
            only_keyframes = False
        elif train_set == "real_synt":
            # Annotate the real and synthetic images (no pbr images)
            data_paths = ['train_real/', 'train_synt/']
            img_types = ['real', 'synt']
            annotation_path = 'train.json'
            only_keyframes = False
        else:
            print("The train set '{}' is not supported".format(train_set))
            exit()
    elif annotation_set == "test_all":
        if test_set == "full":
            # Annotate the full test set
            data_paths = ['test/']
            img_types = ['synt']
            annotation_path = 'test.json'
            only_keyframes = False
        elif test_set == "keyframes":
            # Annotate the Keyframes as designated by most papers
            data_paths = ['test/']
            img_types = ['real']
            annotation_path = 'keyframes.json'
            only_keyframes = True
            keyframe_path = "keyframes.txt"
            with open(keyframe_path) as file:
                keyframe_info = [line.rstrip() for line in file]
        elif test_set == "bop":
            # Annotate only the frames used for the BOP challenge
            data_paths = ['test_bop/']
            img_types = ['real']
            annotation_path = 'test_bop.json'
            only_keyframes = False
        else:
            print("The test set '{}' is not supported".format(test_set))
            exit()
    else:
        print("The annotation set '{}' is not supported.".format(annotation_set))
        exit()

    base_path = '/TmpDataset/' + annotation_set + '/'
    output_base_path = '/opt/project/PoetDataset/annotations/'

    if not os.path.exists(output_base_path):
        os.makedirs(output_base_path, mode=777)


    categories = [
        {'supercategory': 'background', 'id': 0, 'name': 'background'},
        {'supercategory': 'Unnamed-DUMMY#1-1', 'id': 1, 'name': 'Unnamed-DUMMY#1-1'},
        {'supercategory': 'Unnamed1-DUMMY#1-2', 'id': 2, 'name': 'Unnamed1-DUMMY#1-2'},
        {'supercategory': 'Unnamed10-DUMMY#5-2', 'id': 3, 'name': 'Unnamed10-DUMMY#5-2'},
        {'supercategory': 'Unnamed11-DUMMY#5-3', 'id': 4, 'name': 'Unnamed11-DUMMY#5-3'},
        {'supercategory': 'Unnamed12-DUMMY#6-1', 'id': 5, 'name': 'Unnamed12-DUMMY#6-1'},
        {'supercategory': 'Unnamed13-DUMMY#6-2', 'id': 6, 'name': 'Unnamed13-DUMMY#6-2'},
        {'supercategory': 'Unnamed2-DUMMY#1-3', 'id': 7, 'name': 'Unnamed2-DUMMY#1-3'},
        {'supercategory': 'Unnamed3-DUMMY#2-1', 'id': 8, 'name': 'Unnamed3-DUMMY#2-1'},
        {'supercategory': 'Unnamed4-DUMMY#2-2', 'id': 9, 'name': 'Unnamed4-DUMMY#2-2'},
        {'supercategory': 'Unnamed5-DUMMY#3-1', 'id': 10, 'name': 'Unnamed5-DUMMY#3-1'},
        {'supercategory': 'Unnamed6-DUMMY#3-2', 'id': 11, 'name': 'Unnamed6-DUMMY#3-2'},
        {'supercategory': 'Unnamed7-DUMMY#4-1', 'id': 12, 'name': 'Unnamed7-DUMMY#4-1'},
        {'supercategory': 'Unnamed8-DUMMY#4-2', 'id': 13, 'name': 'Unnamed8-DUMMY#4-2'},
        {'supercategory': 'Unnamed9-DUMMY#5-1', 'id': 14, 'name': 'Unnamed9-DUMMY#5-1'}
    ]

    annotations = {'images': [],
                'categories': categories,
                'annotations': []}
    image_id = 0
    annotation_id = 0
    annotations_removed = 0
    for data_path, img_type in zip(data_paths, img_types):
        print("Annotating: {}".format(data_path))
        # Get List of all subdirectories
        image_dirs = [d.name for d in os.scandir(base_path + data_path) if d.is_dir()]
        image_dirs.sort()

        for img_dir in image_dirs:
            img_dir_path = base_path + data_path + img_dir + '/'
            print("Image Directory: {}".format(img_dir_path))
            img_names = [img for img in os.listdir(img_dir_path + 'rgb/') if img[img.rfind('.'):] in ['.png', '.jpg']]
            img_names.sort()
            with open(img_dir_path + 'scene_gt_info.json', 'r') as f:
                bbox_annotations = json.load(f)
            with open(img_dir_path + 'scene_gt.json', 'r') as f:
                pose_annotations = json.load(f)
            with open(img_dir_path + 'scene_camera.json', 'r') as f:
                camera_annotations = json.load(f)
            # Check if annotation length is the same
            n_imgs = len(img_names)
            if len(bbox_annotations) != n_imgs:
                raise ValueError
            if len(pose_annotations) != n_imgs:
                raise ValueError
            if len(camera_annotations) != n_imgs:
                raise ValueError

            # Iterate over all images and annotations and create dict entries
            for img_name, b_k, p_k, c_k in zip(img_names, bbox_annotations, pose_annotations, camera_annotations):
                if only_keyframes:
                    if img_dir[2:] + '/' + img_name[:img_name.rfind('.png')] not in keyframe_info:
                        # Skip images that are not Keyframes
                        continue
                img_path = img_dir_path + 'rgb/' + img_name
                img_annotation_counter = 0
                file_name = data_path + img_dir + '/rgb/' + img_name
                bbox_data = bbox_annotations[b_k]
                pose_data = pose_annotations[p_k]
                camera_data = camera_annotations[c_k]

                for bbox, pose, in zip(bbox_data, pose_data):
                    # If percentage of visible pixels is close to 0 --> skip
                    # In the BOP challenge all bounding boxes are annotated regardless of whether the bounding boxes are visible or not
                    if bbox['visib_fract'] < 0.1:
                        annotations_removed += 1
                        continue
                    # Check if bbox starts / ends outside of image --> set to 0 or img boundary simply
                    x1 = bbox['bbox_obj'][0]
                    y1 = bbox['bbox_obj'][1]
                    x2 = bbox['bbox_obj'][0] + bbox['bbox_obj'][2]
                    y2 = bbox['bbox_obj'][1] + bbox['bbox_obj'][3]

                    if x1 < 0:
                        # Adjust upper left and width
                        bbox['bbox_obj'][2] = bbox['bbox_obj'][2] + bbox['bbox_obj'][0]
                        bbox['bbox_obj'][0] = 0

                    if y1 < 0:
                        # Adjust upper left and height
                        bbox['bbox_obj'][3] = bbox['bbox_obj'][3] + bbox['bbox_obj'][1]
                        bbox['bbox_obj'][1] = 0

                    if x2 >= 640:
                        # Adjust width
                        bbox['bbox_obj'][2] = 640 - bbox['bbox_obj'][0] - 1

                    if y2 >= 480:
                        # Adjust height
                        bbox['bbox_obj'][3] = 480 - bbox['bbox_obj'][1] - 1

                    obj_annotation = {
                        'id': annotation_id,
                        'image_id': image_id,
                        'relative_pose': {
                            'position': [t / 1000.0 for t in pose['cam_t_m2c']],
                            'rotation': pose['cam_R_m2c']
                        },
                        'bbox': bbox['bbox_obj'],
                        'bbox_info': bbox,
                        'area': bbox['bbox_obj'][2] * bbox['bbox_obj'][3],
                        'iscrowd': 0,
                        'category_id': pose['obj_id']
                    }

                    annotations['annotations'].append(obj_annotation)
                    img_annotation_counter += 1
                    annotation_id += 1

                # Check if there are annotations for the image, otherwise skip
                if img_annotation_counter == 0:
                    print("Image skipped! No annotations valid!")
                    continue
                img_annotation = {
                    'file_name': file_name,
                    'id': image_id,
                    'width': 640,
                    'height': 480,
                    'intrinsics': camera_data['cam_K'],
                    'type': img_type
                }

                annotations['images'].append(img_annotation)
                image_id += 1

    print("\nAnnotations Removed: {}".format(annotations_removed))
    print("\nAnnotations kept: {}".format(annotation_id))
    print(output_base_path + annotation_path)
    with open(output_base_path + annotation_path, 'w') as out_file:
        json.dump(annotations, out_file, indent=4)